# Parallel Computing Implementations in C

## Overview
Αυτή η αναφορά εξετάζει δύο προγράμματα C που έχουν σχεδιαστεί για παράλληλο υπολογισμο μιας μαθηματικής συνάρτησης. Και τα δύο προγράμματα επιδεικνύουν τη χρήση παραλληλισμού που βασίζεται σε διεργασίες, κοινής μνήμης και υπολογίζουν το ολοκλήρωμα της συνάρτησης \( f(x) = \sin(\cos(x)) \). Ο βασικός τους σκοπός είναι να παρουσιάσουν διαφορετικές προσεγγίσεις για παράλληλο υπολογισμο στη C.

## Ομοιότητες
1. **Parallelism**: Και τα δύο προγράμματα χρησιμοποιούν παραλληλισμό που βασίζεται σε διεργασίες δημιουργώντας πολλαπλές διεργασίες χρησιμοποιώντας την `fork()` system call.
2. **Shared memory**: Χρησιμοποιούν shared memory (`mmap()`) για επικοινωνία μεταξύ διεργασιών για την αποθήκευση των αποτελεσμάτων των υπολογισμών που εκτελούνται από child processes.

## Υλοποίηση
1. **`integral_mc_shm_sem.c`**:
    - Εφαρμόζει την Monte Carlo integration, όπου κάθε child process λαμβάνει τυχαία δείγματα σημείων και ενημερώνει ένα shared result.
    - Χρησιμοποιεί έναν semaphore για να συγχρονίσει την πρόσβαση στην shared result var.
    - Βασίζεται στη δημιουργία τυχαίων αριθμών για δειγματοληψία στη διαδικασία ολοκλήρωσης.

2. **`integral_mc_shm.c`**:
    - Χρησιμοποιεί μια ντετερμινιστική προσέγγιση για την ολοκλήρωση, διαιρώντας την περιοχή του ολοκληρώματος ομοιόμορφα μεταξύ των child processes.
    - Κάθε child process υπολογίζει το ολοκλήρωμα στο εκχωρημένο subinterval της και αποθηκεύει το αποτέλεσμα στην shared memory .
    - Αποφεύγει τη χρήση semaphore, καθώς δεν υπάρχει ταυτόχρονη λειτουργία εγγραφής στην ίδια θέση μνήμης.

## Κύριες διαφορές και επιπτώσεις στην απόδοση
1. **Μέθοδος ενσωμάτωσης**:
    - **`integral_mc_shm_sem.c`**: Χρησιμοποιεί μια στοχαστική μέθοδο (Monte Carlo), η οποία μπορεί να οδηγήσει σε διαφορετική ακρίβεια με βάση τον αριθμό των δειγμάτων και την ποιότητα της τυχαιότητας.
    - **`integral_mc_shm.c`**: Χρησιμοποιεί μια ντετερμινιστική προσέγγιση ολοκλήρωσης βάσει τμήματος, η οποία είναι πιο προβλέψιμη και συχνά πιο ακριβής για έναν δεδομένο αριθμό δειγμάτων.

2. **Μηχανισμός Συγχρονισμού**:
    - **`integral_mc_shm_sem.c`**: Απαιτεί μηχανισμό συγχρονισμού (semaphore) για την αποτροπή race conditions κατά την ενημέρωση των κοινόχρηστων αποτελεσμάτων.
    - **`integral_mc_shm.c`**: Δεν απαιτεί μηχανισμούς συγχρονισμού λόγω ανεξάρτητων τμημάτων μνήμης για κάθε διεργασία.

3. **Προτιμήσεις απόδοσης**:
    - **Στοχαστική έναντι ντετερμινιστικής**: Η μέθοδος Monte Carlo στο `integral_mc_shm_sem.c` ενδέχεται να μην είναι τόσο αποτελεσματική όσον αφορά τη σύγκλιση σε ένα ακριβές αποτέλεσμα σε σύγκριση με την ντετερμινιστική προσέγγιση στο `integral_mc_shm.c`.
    - **Επιβάρυνση συγχρονισμού**: Ο σηματοφόρος στο `integral_mc_shm_sem.c` εισάγει πρόσθετες επιβαρύνσεις, οι οποίες ενδέχεται να επηρεάσουν την απόδοση, ειδικά για μεγαλύτερο αριθμό διεργασιών.
    - **Predictability**: Η ντετερμινιστική φύση του `integral_mc_shm.c` καθιστά την απόδοση και την ακρίβειά του πιο προβλέψιμες, κάτι που μπορεί να είναι επωφελές σε πολλές εφαρμογές.

## Συμπέρασμα
Ενώ και τα δύο προγράμματα παρουσιάζουν την ικανότητα του παραλληλισμού βάσει διεργασιών στη C για αριθμητική ολοκλήρωση, οι διαφορετικές προσεγγίσεις τους -στοχαστική με συγχρονισμό (`integral_mc_shm_sem.c`) έναντι ντετερμινιστικής χωρίς συγχρονισμό (`integral_mc_shm.c`) - υπογραμμίζουν βασικές πτυχές στο σχεδιασμό παράλληλων υπολογιστών. Η επιλογή μεταξύ αυτών των μεθόδων εξαρτάται από τις συγκεκριμένες απαιτήσεις για ακρίβεια, απόδοση, προβλεψιμότητα της εφαρμογής και τις ανάγκες για συγχρονισμό.